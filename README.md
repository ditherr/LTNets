<h1 align="center">
   ğŸ¤–Transformers x LLM x Neural NetsğŸ¤–
</h1>

<h3 align="center">
    <b>"Autobots, Rolls Out!!"<b> -Optimus Prime
</h3>

This repository is the result of my **Personal Learning about Neural Networks, Large Langugage Models, and Transformers focusing on NLP**. There are a bunch of good or bad materials, codes, tutorials, documentations, books, papers, videos, courses, and more. Some of them are very important, interesting, and worth deepening, some of them are just a piece of cake (not that important - just a note something like that, but still you can check that out).

## ğŸ§©Materials

### ğŸ§¬Neural Networks - (*NLP*)
1. [Micrograd](https://github.com/karpathy/micrograd.git)
2. [Makemore](https://github.com/karpathy/makemore.git)
3. [NanoGPT](https://github.com/karpathy/nanoGPT)
4. PyTorch
5. Project

### ğŸ¤–Transformers (*NLP*)
1. Transformer Model
2. Transformers
3. Fine-Tuning Pretrained Model
4. Sharing Models
5. Datasets
6. The Tokenizers

## ğŸ—ƒï¸Documentations
A list of papers, videos, and books related to this repository.

### ğŸ“œPapers

| Title | Description | Paper |
|-------|-------------|-------|
| Attention Is All You Need | - | <a href="https://arxiv.org/abs/1706.03762"><img src="https://img.shields.io/badge/paper-white"></a>
| ReAct: Synergizing Reasoning And Acting in Language Models | - | <a href="https://arxiv.org/abs/2210.03629"><img src="https://img.shields.io/badge/paper-white"></a>
| Seq-to-Seq Learning with Neural Networks | - | <a href="https://arxiv.org/abs/1409.3215"><img src="https://img.shields.io/badge/paper-white"></a>
| RAG for Knowledge-Intensive NLP Taks | - | <a href="https://arxiv.org/abs/2005.11401"><img src="https://img.shields.io/badge/paper-white"></a>
| LoRA: Low-Rank Adaptation of LLM | - | <a href="https://arxiv.org/abs/2106.09685"><img src="https://img.shields.io/badge/paper-white"></a>
| Improving Language Understanding by GPT | - | <a href="https://cdn.openai.com/research-covers/language-unsupervised/language_understanding_paper.pdf"><img src="https://img.shields.io/badge/paper-white"></a>
| BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding | - | <a href="https://arxiv.org/abs/1810.04805"><img src="https://img.shields.io/badge/paper-white"></a>
| DistilBERT, a distilled version of BERT: smaller, faster, cheaper and lighte | - | <a href="https://arxiv.org/abs/1910.01108"><img src="https://img.shields.io/badge/paper-white"></a>
| BART: Denoising Sequence-to-Sequence Pre-training for Natural Language Generation, Translation, and Comprehension | - | <a href="https://arxiv.org/abs/1910.13461"><img src="https://img.shields.io/badge/paper-white"></a>
| The Pile: An 800GB Dataset of Diverse Text for Language Modeling | - | <a href="https://arxiv.org/abs/2101.00027"><img src="https://img.shields.io/badge/paper-white"></a>
| Model Cards for Model Reporting | - | <a href="https://arxiv.org/abs/1810.03993"><img src="https://img.shields.io/badge/paper-white"></a>
| Deep Residual Learning for Image Recognition | - | <a href="https://arxiv.org/abs/1512.03385"><img src="https://img.shields.io/badge/paper-white"></a>
| Dropout: A Simple Way to Prevent Neural Networks from Overfitting | - | <a href="https://www.cs.toronto.edu/~rsalakhu/papers/srivastava14a.pdf"><img src="https://img.shields.io/badge/paper-white"></a>
| - | - | - |

### ğŸ‘¨â€ğŸ«Courses

#### ğŸ£Fundamental
| Title | Description | Link |
|-------|-------------|------|
| CS50: Introduction to Computer Science | - | <a href="https://cs50.harvard.edu/x/2024/"><img src="https://img.shields.io/badge/course-green"></a> |
| CS50: Introduction to Programming with Python | - | <a href="https://cs50.harvard.edu/python/2022/"><img src="https://img.shields.io/badge/course-green"></a> |
| Machine Learning Specialization | - | <a href="https://www.coursera.org/specializations/machine-learning-introduction"><img src="https://img.shields.io/badge/course-green"></a> |
| DeepLearning.AI TensorFlow Developer Professional Certificate | - | <a href="https://www.coursera.org/professional-certificates/tensorflow-in-practice"><img src="https://img.shields.io/badge/course-green"></a> |
| CS50: Introduction to Artificial Intelligence with Python | - | <a href="https://cs50.harvard.edu/ai/2024/"><img src="https://img.shields.io/badge/course-green"></a>
| - | - | - |

#### ğŸ¤–AI/ML x LLM
| Title | Description | Link |
|-------|-------------|------|
| Neural Networks: Zero to Hero | - | <a href="https://karpathy.ai/zero-to-hero.html"><img src="https://img.shields.io/badge/course-blue"></a> |
| Transformers | - | <a href="https://huggingface.co/docs/transformers/index"><img src="https://img.shields.io/badge/course-blue"></a> |
| Transformers - NLP | - | <a href="https://huggingface.co/learn/nlp-course/en/chapter1/1"><img src="https://img.shields.io/badge/course-blue"></a> |
| Generative AI Course With Langchain and Huggingface | - | <a href="https://www.udemy.com/course/complete-generative-ai-course-with-langchain-and-huggingface"><img src="https://img.shields.io/badge/course-blue"></a> |
| Natural Language Processing in TensorFlow | - | <a href="https://www.coursera.org/learn/natural-language-processing-tensorflow"><img src="https://img.shields.io/badge/course-blue"></a> |
| Complete Machine Learning,NLP Bootcamp MLOPS & Deployment | - | <a href="https://www.udemy.com/course/complete-machine-learning-nlp-bootcamp-mlops-deployment/"><img src="https://img.shields.io/badge/course-blue"></a> |
| - | - | - |


### ğŸï¸Videos

| Title | Description | Link |
|-------|-------------|------|
| ğŸš€Neural Networks: Zero to Hero | - | <a href="https://www.youtube.com/playlist?list=PLAqhIrjkxbuWI23v9cThsA9GvCAUhRvKZ"><img src="https://img.shields.io/badge/video-red"></a> |
| - | - | - |


### ğŸ“šOthers
| Title | Description | Link |
|-------|-------------|------|
| The Illustrated Transformer | - | <a href="https://jalammar.github.io/illustrated-transformer/"><img src="https://img.shields.io/badge/link-orange"></a> |
| Introduction to Attention Mechanism | - | <a href="https://erdem.pl/2021/05/introduction-to-attention-mechanism"><img src="https://img.shields.io/badge/link-orange"></a> |
| - | - | - |